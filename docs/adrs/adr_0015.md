---
title: "Token Budget for Injected Memories"
description: "Implement token budget (default 4000) with content truncation to prevent context bloat when injecting memories."
type: adr
category: performance
tags:
  - token-budget
  - truncation
  - context-management
  - memory-injection
status: published
created: 2025-12-30
updated: 2026-01-15
author: Claude (Architect)
project: subcog
audience:
  - developers
  - architects
confidence: high
completeness: complete
---

# ADR-0015: Token Budget for Injected Memories

## Status

Accepted

## Context

Injecting too many memories or too much content can overwhelm the assistant's context and slow processing. We need to limit injected content to prevent:

1. **Context bloat**: Large memory injections consume tokens that could be used for the actual conversation
2. **Processing delays**: More tokens = longer processing time for the AI assistant
3. **Relevance dilution**: Too many memories may include less relevant content that distracts from the query

## Decision Drivers

### Primary Decision Drivers

1. **Context Window Efficiency**: AI assistants have limited context windows; injected memories should not consume excessive space.

2. **Response Quality**: Smaller, more focused memory injections lead to better AI responses than large dumps of content.

3. **Consistent Behavior**: A fixed budget provides predictable injection sizes regardless of memory collection size.

### Secondary Decision Drivers

1. **Configurability**: Different use cases may require different budgets.

2. **Graceful Degradation**: When budget is exceeded, prioritize more relevant memories over completeness.

## Considered Options

### Option 1: No limit (inject all relevant memories)

**Description**: Inject all memories that match the search query without any truncation.

**Advantages**:
- Complete information available
- Simple implementation

**Disadvantages**:
- Can overwhelm context window
- Unpredictable injection sizes
- May include marginally relevant content

### Option 2: Fixed memory count limit

**Description**: Limit to N memories regardless of content size.

**Advantages**:
- Simple to implement
- Predictable count

**Disadvantages**:
- Inconsistent token usage (short vs long memories)
- May waste budget or exceed it

### Option 3: Token budget with truncation (Chosen)

**Description**: Set a token budget and truncate memory previews to fit within it.

**Advantages**:
- Consistent context usage
- Predictable behavior
- Full content accessible via URN

**Disadvantages**:
- Truncation may hide important details
- Requires token estimation

## Decision

We will implement a **token budget** with content truncation:

- Default: 4000 tokens for injected memories
- Memory content truncated to ~200 chars for preview
- Full content available via memory URN if needed
- Budget configurable via `max_tokens` setting

## Consequences

### Positive

- Prevents context bloat
- Consistent injection size
- Memory URN provides access to full content
- Predictable performance characteristics

### Negative

- Truncation may hide important details
- Fixed budget may not be optimal for all cases
- Token estimation is approximate

### Neutral

- Budget configurable via `max_tokens`
- Preview length configurable via `preview_length`

## More Information

- **Date:** 2025-12-30
- **Source:** SPEC-2025-12-30-001: Proactive Memory Surfacing

## Audit

### 2026-01-15

**Status:** Compliant

**Findings:**

| Finding | Files | Lines | Assessment |
|---------|-------|-------|------------|
| Default max_tokens=4000 and preview_length=200 configured | `src/hooks/search_context.rs` | L13-L38 | compliant |
| Injected memory assembly enforces max token budget with truncation | `src/hooks/search_context.rs` | L412-L437 | compliant |

**Summary:** Injected memories respect the configured token budget and truncate previews as needed.

**Action Required:** None
