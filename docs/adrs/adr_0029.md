---
title: "Existing LLM Provider Infrastructure"
description: "Reuse existing LlmProvider trait from src/llm/mod.rs for enrichment to leverage proven multi-provider infrastructure."
type: adr
category: architecture
tags:
  - llm-provider
  - infrastructure
  - reuse
  - abstraction
status: published
created: 2026-01-01
updated: 2026-01-04
author: Claude (Architect)
project: subcog
technologies:
  - rust
  - anthropic
  - openai
  - ollama
audience:
  - developers
  - architects
confidence: high
completeness: complete
---

# ADR-0029: Existing LLM Provider Infrastructure

## Status

Accepted

## Context

How to implement LLM calls for enrichment?

- Use existing `LlmProvider` trait
- Implement new MCP sampling handler
- Direct API calls

## Decision

We will use the **existing `LlmProvider` trait** from `src/llm/mod.rs`.

## Consequences

### Positive

- Reuses proven infrastructure
- Supports multiple providers (Anthropic, OpenAI, Ollama, LM Studio)
- Configuration already exists
- Error handling patterns established

### Negative

- MCP sampling remains unimplemented (declared but no handler)
- Tighter coupling to local LLM config

**Note:** MCP sampling implementation is out of scope for this spec.

## More Information

- **Date:** 2026-01-01
- **Source:** SPEC-2026-01-01-002: Prompt Variable Context-Aware Extraction

## Audit

### 2026-01-04

**Status:** Compliant

**Findings:**

| Finding | Files | Lines | Assessment |
|---------|-------|-------|------------|
| LlmProvider trait defines provider interface | `src/llm/mod.rs` | L180-L243 | compliant |

**Summary:** LLM provider trait is the central abstraction used by services.

**Action Required:** None
