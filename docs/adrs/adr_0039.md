---
title: "Backward Compatibility with Existing Memories"
description: "Support backward compatible memories with optional embeddings and provide manual migration tool for gradual upgrade path."
type: adr
category: migration
tags:
  - backward-compatibility
  - migration
  - embeddings
  - upgrade-path
status: published
created: 2026-01-02
updated: 2026-01-04
author: Claude (Architect)
project: subcog
related:
  - adr_0050.md
audience:
  - developers
  - architects
  - operators
confidence: high
completeness: complete
---

# ADR-0039: Backward Compatibility with Existing Memories

## Status

Accepted (partially superseded by [ADR-0050](adr_0050.md))

**Supersession Note:** [ADR-0050](adr_0050.md) establishes a "fresh start" policy where legacy git-notes data is not migrated. This means:

- The migration tooling described in this ADR (`subcog migrate embeddings`) is no longer required for legacy data
- Migration status reporting is no longer a compliance requirement
- This ADR remains relevant for its **optional embeddings design pattern**, which is still used for memories created during the transition period or when embedding generation fails

## Context

### Problem Statement

Subcog's evolution from the Python git-notes-memory-manager to the Rust rewrite introduced semantic embeddings as a core feature. Existing installations have accumulated memories stored in Git Notes without embedding vectors. The system must handle this transition gracefully without disrupting existing users or losing access to their accumulated knowledge.

### Historical Background

The original git-notes-memory-manager (Python) stored memories as JSON documents in Git Notes refs:

```
refs/notes/subcog/decisions
refs/notes/subcog/patterns
refs/notes/subcog/learnings
refs/notes/subcog/context
```

These memories contained:
- Content (the actual decision, pattern, or learning text)
- Metadata (timestamps, tags, namespace)
- No embedding vectors (semantic search was not supported)

The Rust rewrite (Subcog) introduces:
- SQLite-based persistence layer
- FTS5 full-text search index
- usearch HNSW vector index for semantic search
- Embedding vectors generated via fastembed (all-MiniLM-L6-v2)

### Migration Challenge

The transition creates several technical challenges:

1. **Schema Evolution**: New memories have an `embedding` field (384-dimensional f32 vector, ~1.5KB per memory). Old memories lack this field entirely.

2. **Search Behavior**: Vector search requires embeddings. Memories without embeddings cannot participate in semantic similarity ranking.

3. **Bulk Processing**: Generating embeddings for existing memories is computationally expensive (~28ms per memory, ~28 seconds for 1000 memories).

4. **User Disruption**: Forcing immediate migration would block users until all embeddings are generated, potentially for minutes on large installations.

5. **Failure Handling**: Embedding generation can fail (ONNX runtime issues, out-of-memory, corrupt input). Failed migrations must not corrupt the memory store.

### Quantitative Assessment

Based on the git-notes history:
- 645 existing memories across repositories
- Average memory content: ~500 characters
- Estimated migration time: ~18 seconds (645 x 28ms)
- Embedding storage overhead: ~970KB (645 x 1.5KB)

While 18 seconds is not catastrophic, the migration must handle:
- Interruptions (user kills process, system crash)
- Partial completions (resume from where it stopped)
- Concurrent access (other processes reading memories during migration)

## Decision Drivers

### Primary Drivers

1. **Zero User Disruption (Weight: 35%)**
   - Users should be able to use Subcog immediately after upgrade
   - No mandatory blocking migration on first run
   - Existing workflows must continue functioning
   - Search should return results, even if not semantically optimal

2. **Data Integrity (Weight: 30%)**
   - No memory loss during migration
   - Partial migrations must not corrupt the store
   - Rollback must be possible if migration fails
   - Original content must remain unchanged

3. **Gradual Adoption (Weight: 20%)**
   - Users can migrate at their own pace
   - Migration can be paused and resumed
   - No "all or nothing" requirement
   - Resource consumption under user control

4. **Implementation Simplicity (Weight: 15%)**
   - Minimize code paths for handling mixed states
   - Clear separation between migration and normal operation
   - Testable migration logic
   - Maintainable codebase

### Secondary Drivers

5. **Observability**
   - Users can check migration status
   - Progress visible during migration
   - Clear indication of what needs migration

6. **Performance Impact**
   - Migration should not impact normal operation latency
   - Background migration option for large installations
   - Batching for efficient embedding generation

7. **Future Compatibility**
   - Design should accommodate future schema changes
   - Pattern reusable for other optional fields
   - Support for embedding model upgrades (re-embedding)

## Considered Options

### Option 1: Breaking Change - Require All Embeddings

**Description**: Refuse to load memories without embeddings. Force migration before any operation.

**Implementation Approach**:
```rust
pub struct Memory {
    pub embedding: Vec<f32>,  // Required, not Option
    // ...
}

fn load_memory(row: &Row) -> Result<Memory> {
    let embedding = row.get::<_, Vec<u8>>("embedding")?;
    if embedding.is_empty() {
        return Err(Error::MigrationRequired);
    }
    // ...
}
```

**Advantages**:
- Simplest code paths (no Option handling)
- Guaranteed consistent search behavior
- No mixed-state complexity

**Disadvantages**:
- Blocks users until migration completes
- Large installations face multi-minute delays on first use
- Migration failures prevent any usage
- Poor user experience for upgrades
- Risk of data loss if migration corrupted

**Risk Assessment**: High risk of user frustration and potential data loss.

**Why Not Selected**: Violates zero-disruption principle. Unacceptable UX for existing users.

### Option 2: Backward Compatible with Optional Embeddings (Selected)

**Description**: Make embeddings optional in the schema. Memories without embeddings participate in text search but not vector search.

**Implementation Approach**:
```rust
pub struct Memory {
    pub embedding: Option<Vec<f32>>,  // None for old memories
    // ...
}

fn search(&self, query: &str) -> Vec<SearchResult> {
    let text_results = self.text_search(query);      // All memories
    let vector_results = self.vector_search(query);  // Only embedded
    self.fuse_with_rrf(text_results, vector_results)
}
```

**Advantages**:
- Zero disruption to existing users
- Immediate usability after upgrade
- Graceful degradation (text search always works)
- Clear upgrade path at user's pace
- Robust to embedding failures

**Disadvantages**:
- Code must handle Option<Vec<f32>> throughout
- Old memories invisible to pure vector search
- Migration status tracking needed
- Slightly more complex search logic

**Risk Assessment**: Low risk. Graceful degradation ensures continued operation.

**Why Selected**: Best balance of user experience, safety, and maintainability.

### Option 3: Auto-Migrate on Access

**Description**: Generate embeddings automatically when a memory is accessed (read or search hit).

**Implementation Approach**:
```rust
fn get_memory(&self, id: &MemoryId) -> Result<Memory> {
    let mut memory = self.storage.load(id)?;
    if memory.embedding.is_none() {
        let embedding = self.embedder.embed(&memory.content)?;
        memory.embedding = Some(embedding);
        self.storage.update_embedding(id, &embedding)?;
    }
    Ok(memory)
}
```

**Advantages**:
- Transparent to users
- No explicit migration step
- Embeddings generated as needed
- Eventually consistent

**Disadvantages**:
- Unpredictable latency spikes (28ms+ on first access)
- Search results change between queries as more memories get embedded
- Write operations during reads (transactional complexity)
- Difficult to test deterministically
- Resource spikes if many memories accessed simultaneously

**Risk Assessment**: Medium risk. Latency unpredictability and transactional complexity.

**Why Not Selected**: Unpredictable latency violates performance expectations. Changing search results confuse users.

### Option 4: Background Auto-Migration

**Description**: Start a background thread on startup that gradually migrates all memories without embeddings.

**Implementation Approach**:
```rust
fn start_background_migration(&self) {
    tokio::spawn(async move {
        let unmigrated = self.storage.get_unmigrated_memories().await?;
        for batch in unmigrated.chunks(100) {
            let embeddings = self.embedder.embed_batch(batch).await?;
            self.storage.update_embeddings_batch(batch, embeddings).await?;
            tokio::time::sleep(Duration::from_millis(100)).await; // Throttle
        }
    });
}
```

**Advantages**:
- Transparent to users
- Eventual full migration
- No explicit user action required
- Throttling prevents resource exhaustion

**Disadvantages**:
- Background resource consumption without user consent
- Difficult to pause or control
- May interfere with user operations
- Completion time unpredictable
- Harder to debug and monitor
- Potential conflicts with manual operations

**Risk Assessment**: Medium risk. Background processes can surprise users with resource usage.

**Why Not Selected**: Resource consumption without explicit user consent is problematic. Users should control when migration happens.

### Option 5: Manual Migration Tool Only

**Description**: Provide a migration command. No automatic migration of any kind.

**Implementation Approach**:
```bash
# User explicitly runs migration
subcog migrate embeddings --batch-size 100 --progress
```

**Advantages**:
- User controls timing and resources
- Clear start and completion
- Can be scheduled (cron, CI/CD)
- Predictable behavior
- Easy to test and debug

**Disadvantages**:
- Requires user action
- Users may forget or not realize migration is needed
- Old memories remain unsearchable until migrated

**Risk Assessment**: Low technical risk. Medium UX risk (users may not migrate).

**Why Partially Selected**: Combined with Option 2 for best of both worlds.

## Decision Outcome

**Selected Approach**: Option 2 (Backward Compatible) + Option 5 (Manual Migration Tool)

### Rationale

The combination provides:

1. **Immediate Usability**: Users can use Subcog immediately after upgrade. Text search works on all memories. Vector search works on new memories and migrated old memories.

2. **User Control**: Migration happens when the user chooses, not automatically. Resources consumed only when explicitly requested.

3. **Graceful Degradation**: Even without migration, the system functions correctly. Old memories are searchable via FTS5 (BM25 ranking). New memories get full semantic search.

4. **Clear Path Forward**: `subcog migrate embeddings` command provides explicit upgrade path. Users understand what is happening and can monitor progress.

5. **Failure Resilience**: If migration fails partway, unmigrated memories remain accessible via text search. No data loss or corruption.

### Implementation Architecture

#### Memory Schema

```rust
/// A captured memory entry.
pub struct Memory {
    /// Unique identifier.
    pub id: MemoryId,
    /// The memory content.
    pub content: String,
    /// The namespace this memory belongs to.
    pub namespace: Namespace,
    /// The domain this memory is associated with.
    pub domain: Domain,
    // ... other fields ...

    /// Optional embedding vector.
    ///
    /// - `Some(vec)`: Memory has been embedded (384 f32 values)
    /// - `None`: Memory predates embeddings or embedding failed
    ///
    /// Search behavior:
    /// - Text search (FTS5/BM25): Works regardless of embedding presence
    /// - Vector search (usearch): Only includes memories with embeddings
    /// - Hybrid search (RRF fusion): Combines both, gracefully handles missing embeddings
    pub embedding: Option<Vec<f32>>,
}
```

#### Search Behavior

```rust
impl SearchService {
    /// Performs hybrid search combining text and vector results.
    ///
    /// Text search (BM25) includes ALL memories regardless of embedding status.
    /// Vector search (HNSW) includes ONLY memories with embeddings.
    /// RRF fusion combines results, naturally handling the asymmetry.
    pub fn search(&self, query: &str) -> Vec<SearchResult> {
        // Text search: All memories participate
        let text_results = self.text_search(query);

        // Vector search: Only embedded memories participate
        let vector_results = if self.has_embeddings() {
            self.vector_search(query)
        } else {
            Vec::new()
        };

        // RRF fusion handles mixed results gracefully
        self.fuse_with_rrf(text_results, vector_results)
    }
}
```

#### Migration Command

```rust
/// Generates embeddings for memories that don't have them.
///
/// # Arguments
/// * `batch_size` - Number of memories to process per batch (default: 100)
/// * `progress` - Show progress bar during migration
/// * `dry_run` - Count memories needing migration without modifying
///
/// # Example
/// ```bash
/// subcog migrate embeddings --batch-size 50 --progress
/// ```
pub async fn migrate_embeddings(
    &self,
    batch_size: usize,
    progress: bool,
    dry_run: bool,
) -> Result<MigrationReport> {
    let unmigrated = self.storage.count_unmigrated()?;

    if dry_run {
        return Ok(MigrationReport {
            total: unmigrated,
            migrated: 0,
            failed: 0
        });
    }

    let mut migrated = 0;
    let mut failed = 0;

    for batch in self.storage.get_unmigrated_batches(batch_size) {
        let contents: Vec<&str> = batch.iter()
            .map(|m| m.content.as_str())
            .collect();

        match self.embedder.embed_batch(&contents) {
            Ok(embeddings) => {
                self.storage.update_embeddings_batch(&batch, embeddings)?;
                migrated += batch.len();
            }
            Err(e) => {
                tracing::warn!(batch_size = batch.len(), error = %e, "Batch embedding failed");
                failed += batch.len();
            }
        }

        if progress {
            // Update progress bar
        }
    }

    Ok(MigrationReport { total: unmigrated, migrated, failed })
}
```

### Behavioral Guarantees

| Scenario | Text Search | Vector Search | Hybrid Search |
|----------|-------------|---------------|---------------|
| All memories have embeddings | Full results | Full results | Full results (RRF) |
| No memories have embeddings | Full results | No results | Text-only results |
| Mixed (some with, some without) | Full results | Partial results | Combined (RRF) |
| Embedding generation fails | Full results | Excluded | Text-only for failed |

### Migration Workflow

```
┌─────────────────────────────────────────────────────────────┐
│                    User Upgrade Path                        │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1. Install new Subcog version                              │
│     └─> Immediate functionality (text search works)         │
│                                                             │
│  2. Check migration status (optional)                       │
│     └─> subcog status --migration                           │
│         "645 memories without embeddings"                   │
│                                                             │
│  3. Run migration when convenient                           │
│     └─> subcog migrate embeddings --progress                │
│         [████████████████████] 645/645 complete             │
│                                                             │
│  4. Full functionality                                      │
│     └─> Vector search now includes all memories             │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

## Consequences

### Positive

1. **Zero Downtime Upgrades**: Users experience no interruption when upgrading from git-notes-memory-manager to Subcog. All existing memories remain immediately accessible via text search.

2. **Graceful Feature Degradation**: The system works correctly at every point in the migration spectrum:
   - 0% migrated: Pure text search (BM25), still useful
   - 50% migrated: Hybrid search favors migrated memories semantically
   - 100% migrated: Full semantic search capability

3. **User-Controlled Resource Usage**: Migration happens when users choose, using resources they allocate. No surprise CPU spikes or memory consumption.

4. **Failure Isolation**: If embedding generation fails for specific memories (malformed content, ONNX errors), those memories remain accessible via text search. Failures do not cascade.

5. **Incremental Migration**: Users can migrate in stages, testing search quality improvements incrementally. Large installations can spread migration over time.

6. **Schema Flexibility**: The `Option<Vec<f32>>` pattern is reusable for future optional fields. When embedding models are upgraded, the same migration infrastructure can re-embed memories.

7. **Testability**: Each state (no embeddings, partial embeddings, full embeddings) can be independently tested. Migration logic is isolated from core search paths.

### Negative

1. **Increased Code Complexity**: Every code path touching embeddings must handle `Option<Vec<f32>>`. This includes:
   - Storage layer serialization/deserialization
   - Search ranking algorithms
   - Memory display formatting
   - Export/import operations

2. **Inconsistent Search Results**: Until migration completes, vector search returns partial results. Users may wonder why some relevant memories do not appear in semantic searches.

3. **Documentation Burden**: Users need to understand the migration process, why it matters, and when to run it. This adds onboarding complexity.

4. **Migration Status Tracking**: The system must track which memories have embeddings, adding queries and potentially indexes to support status reporting.

5. **Long-term Technical Debt**: The Option handling remains in the codebase indefinitely, even after all production installations have migrated. Removing it would require a breaking change.

### Neutral

1. **Hybrid Search Dependency**: The system's resilience depends on hybrid search (RRF fusion of text + vector). This is already a design requirement for quality reasons, so backward compatibility aligns with existing architecture.

2. **Storage Overhead**: Memories without embeddings use less storage (~1.5KB savings per memory). This is temporary and not a significant factor either way.

## Related Decisions

- **ADR-0037**: Model Selection - all-MiniLM-L6-v2 - Defines the embedding model used during migration
- **ADR-0050**: Fresh Start - No Migration of Legacy Data - Supersedes the migration requirement for git-notes data specifically
- **ADR-0004**: Event Bus - Migration progress events can be published for observability

## Implementation Notes

### Database Schema

The SQLite schema accommodates optional embeddings:

```sql
CREATE TABLE memories (
    id TEXT PRIMARY KEY,
    content TEXT NOT NULL,
    namespace TEXT NOT NULL,
    -- ... other columns ...
    embedding BLOB,  -- NULL for unmigrated memories
    created_at INTEGER NOT NULL,
    updated_at INTEGER NOT NULL
);

-- Index for finding unmigrated memories efficiently
CREATE INDEX idx_memories_no_embedding
ON memories(id)
WHERE embedding IS NULL;
```

### Vector Index Handling

The usearch HNSW index only contains memories with embeddings:

```rust
impl VectorIndex {
    /// Adds a memory to the vector index if it has an embedding.
    pub fn index_memory(&mut self, memory: &Memory) -> Result<()> {
        if let Some(ref embedding) = memory.embedding {
            self.index.add(memory.id.as_str(), embedding)?;
        }
        // Silently skip memories without embeddings
        Ok(())
    }

    /// Rebuilds the index from all memories with embeddings.
    pub fn rebuild(&mut self, memories: &[Memory]) -> Result<()> {
        self.index.clear();
        for memory in memories {
            if memory.embedding.is_some() {
                self.index_memory(memory)?;
            }
        }
        Ok(())
    }
}
```

### Migration Idempotency

The migration command is idempotent and resumable:

```rust
/// Gets memories that need embedding generation.
///
/// This query is idempotent: running it multiple times returns
/// only memories that still lack embeddings.
pub fn get_unmigrated_memories(&self, limit: usize) -> Result<Vec<Memory>> {
    let query = "
        SELECT * FROM memories
        WHERE embedding IS NULL
        ORDER BY created_at ASC
        LIMIT ?
    ";
    // ...
}
```

## Links

- [SQLite NULL Handling](https://www.sqlite.org/nulls.html)
- [usearch HNSW Index](https://github.com/unum-cloud/usearch)
- [RRF Fusion Algorithm](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)

## More Information

- **Date:** 2026-01-02
- **Source:** SPEC-2026-01-02: Memory System Critical Fixes
- **Note:** This ADR predates ADR-0050 (Fresh Start). The fresh start decision means no migration is needed for legacy git-notes data specifically, but the optional embeddings pattern remains relevant for:
  - Memories created when embedding generation fails
  - Future embedding model upgrades requiring re-embedding
  - Testing scenarios with mixed embedding states

## Audit

### 2026-01-04

**Status:** Partial (see supersession note)

**Findings:**

| Finding | Files | Lines | Assessment |
|---------|-------|-------|------------|
| Memory embeddings are optional | `src/models/memory.rs` | L60-L63 | compliant |
| Manual embeddings migration command exists | `src/commands/migrate.rs` | L1-L16 | compliant |
| Status command does not report migration state | `src/cli/status.rs` | L1-L17 | no longer required (per ADR-0050) |

**Summary:** Embeddings are optional and manual migration exists. Migration status reporting is no longer a compliance requirement due to ADR-0050's fresh start policy.

**Action Required:** None
