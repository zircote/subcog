---
title: "Observability Expansion Priorities"
description: "Prioritize end-to-end observability with equal MCP and hook instrumentation, focusing on latency SLOs first."
type: adr
category: architecture
tags:
  - observability
  - tracing
  - metrics
  - slo
  - instrumentation
status: accepted
created: 2026-01-04
updated: 2026-01-04
author: Claude (Architect)
project: subcog
technologies:
  - rust
  - opentelemetry
audience:
  - developers
  - architects
confidence: high
completeness: complete
---

# ADR-0060: Observability Expansion Priorities

## Status

Accepted

## Context

### Problem Statement

Subcog operates through multiple execution paths that must be observable for operational health, debugging, and performance optimization:

1. **CLI Commands**: Direct invocation via `subcog capture`, `subcog recall`, etc.
2. **MCP Server**: Model Context Protocol server handling tool invocations from AI assistants
3. **Claude Code Hooks**: Lifecycle hooks (`user_prompt`, `post_tool_use`, `stop`) invoked by Claude Code
4. **Background Operations**: Consolidation, garbage collection, sync operations

Each path has distinct characteristics:

| Path | Invocation Frequency | Latency Sensitivity | User Visibility | Failure Impact |
|------|---------------------|---------------------|-----------------|----------------|
| CLI | Low (manual) | Low | Direct | Immediate feedback |
| MCP | High (per AI request) | High | Indirect (AI response delay) | User frustration |
| Hooks | Very High (every prompt) | Critical (<50ms budget) | Invisible | AI assistant slowdown |
| Background | Low (scheduled) | Low | None | Silent degradation |

The challenge is determining where to invest observability effort first, given limited resources and the need to maintain the <10ms cold start and <50ms hook latency targets.

### Current Observability State

Prior to this decision, Subcog had partial observability:

| Component | Logging | Metrics | Tracing | Audit |
|-----------|---------|---------|---------|-------|
| CLI | Basic | None | None | None |
| MCP Server | Structured | Partial | None | Partial |
| Hooks | Minimal | None | None | None |
| Storage | Debug | None | None | None |
| Embedding | Debug | None | None | None |

This created blind spots:
- No visibility into hook latency distribution
- No correlation between MCP requests and storage operations
- No SLO tracking for critical paths
- Security events mixed with operational logs

### Observability Requirements

Different stakeholders have different observability needs:

**Operators (Production)**:
- SLO compliance dashboards (latency p50/p95/p99)
- Error rate alerts
- Resource utilization metrics
- Capacity planning data

**Developers (Debugging)**:
- Request tracing across components
- Correlation IDs for log aggregation
- Performance profiling data
- Regression detection

**Security/Compliance (Audit)**:
- Immutable operation records
- Access logs with actor attribution
- Data subject request tracking
- Chain-of-custody for memories

### Technical Constraints

Observability must operate within Subcog's performance envelope:

1. **Hook Latency Budget**: Hooks must complete in <50ms to avoid perceptible AI assistant delay. Observability overhead must be <5ms.

2. **Cold Start Target**: <10ms cold start requires lazy initialization of observability infrastructure.

3. **Binary Size**: OpenTelemetry dependencies add ~2MB to binary. Must remain under 100MB total.

4. **Memory Overhead**: Metrics and trace buffers consume memory. Must remain under 50MB total runtime memory.

5. **No External Dependencies for Core**: Core functionality must work without OTLP collector. Observability should enhance but not require external infrastructure.

## Decision Drivers

### Primary Drivers

1. **End-to-End Traceability (Weight: 30%)**
   - A single request should be traceable from entry (hook/MCP/CLI) through storage and back
   - Correlation IDs must propagate across all layers
   - Parent-child relationships between operations must be visible
   - Latency attribution to specific components (embedding, storage, search)

2. **Equal MCP and Hook Priority (Weight: 25%)**
   - Both execution paths serve AI assistants
   - Hook latency directly impacts user experience
   - MCP errors cause visible failures in AI responses
   - Instrumentation parity ensures consistent debugging experience

3. **Latency SLO Focus (Weight: 25%)**
   - Latency is the primary user-visible metric
   - Histograms enable percentile tracking (p50, p95, p99)
   - SLO compliance is measurable and actionable
   - Latency regressions detectable via alerting

4. **Security Event Separation (Weight: 20%)**
   - Security events require different retention and access controls
   - Audit logs must be tamper-evident (HMAC chain)
   - Sensitive data must not leak into general telemetry
   - Compliance requires distinct audit trail

### Secondary Drivers

5. **Incremental Rollout**
   - Observability can be enabled progressively
   - Production systems should not require immediate full instrumentation
   - Feature flags for expensive instrumentation

6. **Standard Protocols**
   - OpenTelemetry for interoperability
   - Prometheus exposition format for metrics
   - Structured JSON logging for aggregation

7. **Low Overhead**
   - Instrumentation must not violate latency budgets
   - Sampling for high-volume paths
   - Lazy initialization for cold start

## Considered Options

### Option 1: Prioritize MCP Instrumentation, Add Hooks Later

**Description**: Focus all observability effort on MCP server first, as it is the primary API surface. Add hook instrumentation in a later phase.

**Implementation Approach**:
```rust
// Phase 1: MCP only
impl McpServer {
    #[tracing::instrument(skip(self))]
    async fn handle_tool(&self, request: ToolRequest) -> Result<ToolResponse> {
        let start = Instant::now();
        let result = self.execute_tool(request).await;
        metrics::histogram!("mcp_tool_latency_ms").record(start.elapsed().as_millis());
        result
    }
}

// Phase 2 (later): Hooks
// ... deferred ...
```

**Advantages**:
- Focused effort on API surface
- MCP is explicit protocol with clear boundaries
- Easier to instrument (request/response model)
- Lower volume than hooks

**Disadvantages**:
- Creates observability gaps for hook-based workflows
- Hook latency regressions invisible until Phase 2
- Debugging cross-path issues impossible
- Hooks are higher volume and more latency-sensitive

**Risk Assessment**: Medium-high. Hook issues would be invisible, risking silent performance degradation.

**Why Not Selected**: Hooks are actually more latency-critical than MCP. Deferring hook instrumentation creates unacceptable blind spots.

### Option 2: Focus on Error Budgets Before Latency

**Description**: Prioritize error rate tracking and alerting before latency metrics. Error budgets are easier to reason about.

**Implementation Approach**:
```rust
// Track success/failure only
metrics::counter!("operations_total", "result" => "success").increment(1);
metrics::counter!("operations_total", "result" => "failure").increment(1);

// Calculate error rate: failure / total
// Alert when error_rate > threshold
```

**Advantages**:
- Error budgets are simple to implement
- Clear pass/fail semantics
- Lower instrumentation overhead
- Easier alerting rules

**Disadvantages**:
- Latency issues are more common than errors in practice
- Slow operations are not errors but still impact UX
- Error budgets require baseline data to set thresholds
- Latency regressions invisible until they cause timeouts (errors)

**Risk Assessment**: Medium. Latency degradation would be invisible until it causes errors.

**Why Not Selected**: In Subcog's context, latency is the primary failure mode. A hook that takes 200ms instead of 20ms is not an "error" but severely impacts user experience.

### Option 3: Sample All Flows Uniformly

**Description**: Apply the same sampling strategy across all execution paths. Simple and consistent.

**Implementation Approach**:
```rust
// 10% sampling for all paths
let sampler = Sampler::TraceIdRatioBased(0.10);

// Same sampling in hooks, MCP, CLI, background
if should_sample() {
    // Full instrumentation
} else {
    // Minimal instrumentation
}
```

**Advantages**:
- Simple, consistent sampling logic
- Predictable observability data volume
- Easy to reason about

**Disadvantages**:
- High-volume flows (hooks) may overwhelm storage even at 10%
- Low-volume flows (background) may have insufficient data
- Security-sensitive events mixed with general telemetry
- One-size-fits-all misses path-specific needs

**Risk Assessment**: Medium. Either over-samples high-volume paths or under-samples low-volume paths.

**Why Not Selected**: Different paths have different characteristics requiring different sampling strategies.

### Option 4: Equal Priority with Latency Focus (Selected)

**Description**: Treat MCP and hooks as equal-priority instrumentation targets. Focus initial SLOs on latency. Separate security events into distinct streams.

**Implementation Approach**:
```rust
// Equal instrumentation for hooks and MCP
#[tracing::instrument(skip(self), fields(correlation_id))]
async fn user_prompt_hook(&self, context: HookContext) -> Result<HookResponse> {
    let start = Instant::now();
    let result = self.process_prompt(context).await;

    // Latency histogram for SLO tracking
    metrics::histogram!("hook_latency_ms", "hook" => "user_prompt")
        .record(start.elapsed().as_millis());

    // Publish to event bus (security events routed separately)
    self.event_bus.publish(MemoryEvent::HookInvoked {
        meta: EventMeta::new("hook", correlation_id),
        hook: "user_prompt".to_string(),
    });

    result
}

// Similar instrumentation for MCP
#[tracing::instrument(skip(self), fields(tool_name, correlation_id))]
async fn execute_tool(&self, request: ToolRequest) -> Result<ToolResponse> {
    let start = Instant::now();
    let result = self.dispatch_tool(request).await;

    metrics::histogram!("mcp_tool_latency_ms", "tool" => request.tool_name)
        .record(start.elapsed().as_millis());

    self.event_bus.publish(MemoryEvent::McpToolExecuted {
        meta: EventMeta::new("mcp", correlation_id),
        tool_name: request.tool_name,
        duration_ms: start.elapsed().as_millis(),
        // ...
    });

    result
}
```

**Advantages**:
- Comprehensive coverage from the start
- Latency SLOs address the most common performance concern
- Separate security streams enable compliance without compromising operations
- Consistent debugging experience across all paths
- Foundation for future observability expansion

**Disadvantages**:
- Broader scope increases initial instrumentation effort
- Requires careful design of security event separation
- More complex configuration (multiple sampling strategies)

**Risk Assessment**: Low. Comprehensive approach reduces blind spots.

**Why Selected**: Best balance of coverage, focus, and maintainability.

## Decision Outcome

**Selected Option**: Equal Priority with Latency Focus (Option 4)

### Rationale

1. **Hook Criticality Recognized**: Hooks execute on every AI assistant interaction. Their latency directly impacts user experience. Treating them as lower priority than MCP would be a mistake.

2. **Latency as Primary Signal**: In Subcog's context, latency degradation is the most likely and most impactful failure mode:
   - Hook taking 100ms instead of 10ms: User perceives AI slowdown
   - MCP tool taking 500ms instead of 50ms: AI response delayed
   - Error rates are typically <1%: Errors are rare but latency affects 100% of requests

3. **Security Separation Essential**: Mixing security events with operational telemetry creates compliance risks:
   - Operational logs may have short retention
   - Security events may contain sensitive metadata
   - Different access control requirements
   - Audit logs require tamper-evidence (HMAC chain)

4. **Foundation for Growth**: Comprehensive instrumentation enables future capabilities:
   - Anomaly detection requires baseline data from all paths
   - Capacity planning requires volume metrics from all paths
   - Performance optimization requires latency attribution across paths

### Implementation Architecture

#### Instrumentation Layers

```
┌─────────────────────────────────────────────────────────────────┐
│                        Entry Points                             │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐   ┌─────────────────┐    │
│  │   CLI   │  │   MCP   │  │  Hooks  │   │   Background    │    │
│  └────┬────┘  └────┬────┘  └────┬────┘   └────────┬────────┘    │
│       │            │            │                 │             │
├───────┴────────────┴────────────┴─────────────────┴─────────────┤
│                    Observability Layer                          │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │  • Correlation ID injection                              │   │
│  │  • Tracing span creation                                 │   │
│  │  • Metrics recording                                     │   │
│  │  • Event bus publication                                 │   │
│  └──────────────────────────────────────────────────────────┘   │
│       │            │            │                 │             │
├───────┴────────────┴────────────┴─────────────────┴─────────────┤
│                      Core Services                              │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐   ┌─────────────────┐    │
│  │ Capture │  │  Recall │  │  Search │   │  Consolidation  │    │
│  └────┬────┘  └────┬────┘  └────┬────┘   └────────┬────────┘    │
│       │            │            │                 │             │
├───────┴────────────┴────────────┴─────────────────┴─────────────┤
│                      Storage Layer                              │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐                          │
│  │ SQLite  │  │  FTS5   │  │ usearch │                          │
│  └─────────┘  └─────────┘  └─────────┘                          │
└─────────────────────────────────────────────────────────────────┘
```

#### Latency SLO Metrics

```rust
// Hook latency histogram with percentile tracking
metrics::histogram!("subcog_hook_latency_ms", "hook" => hook_name)
    .record(duration.as_millis() as f64);

// MCP tool latency histogram
metrics::histogram!("subcog_mcp_tool_latency_ms", "tool" => tool_name)
    .record(duration.as_millis() as f64);

// Storage operation latency
metrics::histogram!("subcog_storage_latency_ms", "operation" => op_name)
    .record(duration.as_millis() as f64);

// Embedding generation latency
metrics::histogram!("subcog_embedding_latency_ms")
    .record(duration.as_millis() as f64);
```

SLO definitions:

| Metric | Target | Alert Threshold |
|--------|--------|-----------------|
| `subcog_hook_latency_ms` p99 | <50ms | >75ms |
| `subcog_hook_latency_ms` p50 | <10ms | >20ms |
| `subcog_mcp_tool_latency_ms` p99 | <500ms | >750ms |
| `subcog_mcp_tool_latency_ms` p50 | <100ms | >200ms |
| `subcog_storage_latency_ms` p99 | <100ms | >150ms |
| `subcog_embedding_latency_ms` p99 | <50ms | >75ms |

#### Trace Sampling Strategy

Different paths require different sampling:

```rust
impl TracingConfig {
    /// Builds a path-aware sampler.
    pub fn build_sampler(&self) -> impl Sampler {
        // Hooks: High volume, sample 1%
        // MCP: Medium volume, sample 10%
        // CLI: Low volume, sample 100%
        // Background: Low volume, sample 100%

        PathAwareSampler {
            hook_ratio: 0.01,
            mcp_ratio: 0.10,
            cli_ratio: 1.0,
            background_ratio: 1.0,
        }
    }
}
```

#### Security Event Separation

Security events flow through a separate channel:

```rust
// Security events: audit-worthy operations
pub enum SecurityEvent {
    MemoryAccessed {
        memory_id: MemoryId,
        accessor: String,
        access_type: AccessType,
    },
    MemoryDeleted {
        memory_id: MemoryId,
        actor: String,
        reason: String,
    },
    DataSubjectRequest {
        subject_id: String,
        request_type: DsrType,
        status: DsrStatus,
    },
    AuthenticationAttempt {
        client_id: Option<String>,
        success: bool,
        reason: Option<String>,
    },
}

// Security events go to audit log (HMAC-chained, separate retention)
impl AuditLogger {
    pub fn log_security_event(&self, event: SecurityEvent) -> Result<()> {
        let entry = AuditEntry::from(event);
        entry.sign(&self.hmac_key, &self.last_hmac)?;
        self.write_entry(&entry)?;
        Ok(())
    }
}
```

#### Correlation ID Propagation

Correlation IDs flow through all layers:

```rust
// Request context carries correlation ID
pub struct RequestContext {
    pub correlation_id: String,
    pub source: &'static str,
    pub start_time: Instant,
}

// Scoped context for the current operation
thread_local! {
    static CURRENT_CONTEXT: RefCell<Option<RequestContext>> = RefCell::new(None);
}

// All operations access correlation ID via context
pub fn current_correlation_id() -> Option<String> {
    CURRENT_CONTEXT.with(|ctx| {
        ctx.borrow().as_ref().map(|c| c.correlation_id.clone())
    })
}

// Events include correlation ID for tracing
pub struct EventMeta {
    pub event_id: String,
    pub correlation_id: Option<String>,  // Propagated from request context
    pub source: &'static str,
    pub timestamp: u64,
}
```

### Observability Stack

```
┌─────────────────────────────────────────────────────────────────┐
│                    Subcog Process                               │
│                                                                 │
│  ┌──────────────┐  ┌───────────────┐  ┌──────────────────────┐  │
│  │   Metrics    │  │   Tracing     │  │    Audit Logging     │  │
│  │  (Prometheus │  │ (OpenTelemetry│  │   (HMAC-chained      │  │
│  │   exporter)  │  │    OTLP)      │  │    JSON lines)       │  │
│  └──────┬───────┘  └──────┬────────┘  └──────────┬───────────┘  │
│         │                 │                      │              │
└─────────┼─────────────────┼──────────────────────┼──────────────┘
          │                 │                      │
          ▼                 ▼                      ▼
    ┌───────────┐    ┌───────────┐         ┌───────────┐
    │Prometheus │    │   OTLP    │         │  Audit    │
    │  /metrics │    │ Collector │         │  Storage  │
    └───────────┘    └───────────┘         └───────────┘
          │                 │
          ▼                 ▼
    ┌───────────┐    ┌───────────┐
    │  Grafana  │    │   Jaeger  │
    │ Dashboard │    │  /Tempo   │
    └───────────┘    └───────────┘
```

### Configuration

Observability is configured via `subcog.toml` and environment variables:

```toml
[observability]
# Enable metrics endpoint
metrics_enabled = true
metrics_port = 9090

# Enable OTLP tracing
tracing_enabled = true
otlp_endpoint = "http://localhost:4317"
sample_ratio = 1.0  # 100% for development

# Audit logging
audit_enabled = true
audit_path = "/var/log/subcog/audit.jsonl"
audit_retention_days = 90

[observability.push_gateway]
# For short-lived processes (hooks)
endpoint = "http://localhost:9091/metrics/job/subcog"
```

Environment overrides:

```bash
# Enable tracing via environment
export SUBCOG_TRACING_ENABLED=true
export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
export SUBCOG_TRACE_SAMPLE_RATIO=0.1

# Enable metrics
export SUBCOG_METRICS_ENABLED=true
export SUBCOG_METRICS_PORT=9090
```

## Consequences

### Positive

1. **Complete Visibility**: All execution paths (CLI, MCP, hooks, background) are instrumented consistently. No blind spots in debugging or performance analysis.

2. **Latency SLO Tracking**: Prometheus histograms enable precise percentile tracking. SLO compliance dashboards show p50/p95/p99 latencies with alerting when thresholds are breached.

3. **End-to-End Tracing**: Correlation IDs propagate through all layers, enabling request reconstruction in distributed tracing tools (Jaeger, Tempo, Zipkin).

4. **Security Compliance**: Security events are separated from operational telemetry with distinct retention, access control, and tamper-evidence (HMAC chain).

5. **Performance Regression Detection**: Latency histograms enable automated detection of performance regressions via statistical comparison (e.g., p95 increased >20% from baseline).

6. **Capacity Planning Data**: Metrics on operation volume, storage size, and resource utilization enable informed capacity planning.

7. **Debugging Efficiency**: When issues occur, developers can:
   - Find correlation ID in error log
   - Query traces by correlation ID
   - View complete request flow
   - Identify latency attribution per component

### Negative

1. **Increased Instrumentation Complexity**: Equal priority for all paths means more code to instrument and maintain. Each entry point requires correlation ID injection, span creation, and metrics recording.

2. **Configuration Complexity**: Multiple sampling strategies, security event routing, and backend configuration require careful documentation and validation.

3. **Resource Overhead**: Full observability adds overhead:
   - Metrics: ~1-2% CPU for recording and exposition
   - Tracing: ~2-5% CPU for span creation and OTLP export
   - Audit: ~1% CPU for HMAC computation and file writes
   - Memory: ~10MB for metric/trace buffers

4. **External Dependencies for Full Value**: While core functionality works without external infrastructure, full observability requires:
   - Prometheus or compatible TSDB for metrics
   - OTLP collector for traces
   - Log aggregation for audit analysis

5. **Learning Curve**: Operators must understand:
   - Prometheus query language for dashboards
   - Trace interpretation for debugging
   - Audit log format for compliance queries

### Neutral

1. **Optional Enablement**: Observability components are opt-in. Production deployments without observability infrastructure operate correctly (just without visibility).

2. **Standard Protocols**: Using OpenTelemetry and Prometheus ensures compatibility with existing observability stacks. No proprietary lock-in.

3. **Sampling Trade-offs**: Lower sampling ratios reduce overhead but increase time to collect statistically significant data. Operators must balance based on volume.

## Related Decisions

- **ADR-0059**: Central Event Bus for Memory Events - Provides event stream for observability consumers
- **ADR-0004**: Event Bus for Cross-Component Communication - Original event bus design
- **ADR-0037**: Model Selection - Embedding latency is a key SLO metric

## Implementation Notes

### Hook Instrumentation Pattern

```rust
pub async fn user_prompt_hook(&self, context: HookContext) -> Result<HookResponse> {
    // 1. Create request context with correlation ID
    let correlation_id = context.correlation_id
        .unwrap_or_else(|| Uuid::new_v4().to_string());
    let _guard = scope_request_context(RequestContext {
        correlation_id: correlation_id.clone(),
        source: "hook:user_prompt",
        start_time: Instant::now(),
    });

    // 2. Create tracing span
    let span = tracing::info_span!(
        "user_prompt_hook",
        correlation_id = %correlation_id,
        otel.kind = "server",
    );
    let _enter = span.enter();

    // 3. Execute with timing
    let start = Instant::now();
    let result = self.process_prompt(&context).await;
    let duration = start.elapsed();

    // 4. Record metrics
    metrics::histogram!("subcog_hook_latency_ms", "hook" => "user_prompt")
        .record(duration.as_millis() as f64);

    // 5. Publish event
    global_event_bus().publish(MemoryEvent::HookInvoked {
        meta: EventMeta::new("hook", Some(correlation_id)),
        hook: "user_prompt".to_string(),
    });

    result
}
```

### Metrics Push for Short-Lived Processes

Hooks are invoked as separate processes. Standard Prometheus pull model does not work. Use push gateway:

```rust
// In hook process
pub fn flush_metrics_on_exit() {
    // Push accumulated metrics to gateway before process exits
    metrics::flush_global();
}

// Ensure flush on all exit paths
impl Drop for HookContext {
    fn drop(&mut self) {
        flush_metrics_on_exit();
    }
}
```

### Trace Context Propagation

For MCP requests that may span multiple operations:

```rust
// Extract trace context from incoming request
let parent_context = extract_trace_context(&request.headers);

// Create child span
let span = tracer
    .span_builder("mcp_tool_execute")
    .with_parent_context(parent_context)
    .start(&tracer);

// Inject trace context into outgoing requests (if any)
inject_trace_context(&mut outgoing_request.headers, &span.context());
```

## Links

- [OpenTelemetry Rust SDK](https://docs.rs/opentelemetry)
- [Prometheus Rust Client](https://docs.rs/prometheus)
- [Grafana Loki for Log Aggregation](https://grafana.com/oss/loki/)
- [SLO Best Practices](https://sre.google/sre-book/service-level-objectives/)
- [Distributed Tracing in Practice](https://www.oreilly.com/library/view/distributed-tracing-in/9781492056621/)

## More Information

- **Date:** 2026-01-04
- **Plan:** `docs/spec/active/observability-eventbus-plan.md`
- **Implementation:** `src/observability/metrics.rs`, `src/observability/tracing.rs`, `src/security/audit.rs`
