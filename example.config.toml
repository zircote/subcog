# Subcog full configuration with sane defaults.

repo_path = "."
data_dir = ".subcog"
max_results = 10
default_search_mode = "hybrid" # text, vector, hybrid

# Storage configuration for each domain scope.
# Available backends: sqlite, filesystem, postgresql, redis
# Note: All scopes now use SQLite by default with domain faceting (repo/branch/path).
[storage]

[storage.project]
backend = "sqlite"
# Uses the same SQLite database as user scope, with project-specific facets
# (repo URL, branch name, working directory) for isolation.
# path = "~/.config/subcog/memories.db"  # defaults to user's SQLite database

[storage.user]
backend = "sqlite"
path = "~/.config/subcog/memories.db"
# Alternative: filesystem
# backend = "filesystem"
# path = "~/.config/subcog/prompts/"
# Alternative: postgresql
# backend = "postgresql"
# connection_string = "postgresql://user:pass@localhost/subcog"
# Alternative: redis (requires 'redis' feature)
# backend = "redis"
# connection_string = "redis://localhost:6379"

[storage.org]
backend = "sqlite"
# Not yet fully implemented - organization-scoped storage is planned.
# For shared storage, use postgresql:
# backend = "postgresql"
# connection_string = "postgresql://user:pass@localhost/subcog_org"

[features]
secrets_filter = false
pii_filter = false
multi_domain = false
audit_log = false
llm_features = false
auto_capture = false
consolidation = false

[llm]
provider = "anthropic" # anthropic, openai, ollama, lmstudio
model = "claude-sonnet-4-20250514"
api_key = "" # leave empty to use env vars
base_url = "https://api.anthropic.com/v1"
timeout_ms = 30000
connect_timeout_ms = 3000
max_retries = 0
retry_backoff_ms = 100
breaker_failure_threshold = 3
breaker_reset_ms = 30000
breaker_half_open_max_calls = 1
latency_slo_ms = 2000
error_budget_ratio = 0.05
error_budget_window_secs = 300

[search_intent]
enabled = true
use_llm = true
llm_timeout_ms = 200
min_confidence = 0.5
base_count = 5
max_count = 15
max_tokens = 4000

# Namespace weights for intent-based search prioritization.
# Weights are multipliers applied to relevance scores. Higher = more priority.
# Default is 1.0. Configure per-intent to boost specific namespaces.
#
# [search_intent.weights.howto]
# patterns = 1.5       # How-to questions prioritize patterns
# learnings = 1.3
# decisions = 1.0
#
# [search_intent.weights.troubleshoot]
# blockers = 1.5       # Troubleshooting prioritizes blockers
# learnings = 1.3
# decisions = 1.0
#
# [search_intent.weights.location]
# decisions = 1.5      # Location queries prioritize decisions/context
# context = 1.3
# patterns = 1.0
#
# [search_intent.weights.explanation]
# decisions = 1.5      # Explanation queries prioritize decisions
# context = 1.3
# patterns = 1.0
#
# [search_intent.weights.comparison]
# decisions = 1.5      # Comparisons prioritize decisions/patterns
# patterns = 1.3
# learnings = 1.0
#
# [search_intent.weights.general]
# decisions = 1.2      # General queries have balanced weights
# patterns = 1.2
# learnings = 1.0

[observability.logging]
format = "json" # json, pretty
level = "info"
filter = "subcog=info"
# file = "/opt/homebrew/var/log/subcog/subcog.log" # Homebrew: /opt/homebrew/var/log/ (Apple Silicon) or /usr/local/var/log/ (Intel)

[observability.tracing]
enabled = false
sample_ratio = 1.0
service_name = "subcog"
resource_attributes = []

[observability.tracing.otlp]
endpoint = "http://localhost:4317"
protocol = "grpc" # grpc, http

[observability.metrics]
enabled = false
port = 9090

[observability.metrics.push_gateway]
endpoint = "" # full push gateway URL, including /metrics/job/<job>
username = ""
password = ""
use_http_post = true # POST accumulates metrics, PUT replaces all (default: true)

# Prompt customization - extend or override the default LLM system prompts.
# Use this to add domain-specific guidance, compliance requirements, or custom behaviors.
[prompt]
# Additional identity context (appended to subcog's identity section).
# Use this to describe your environment, compliance requirements, or organizational context.
# identity_addendum = """
# You are operating in a healthcare environment subject to HIPAA regulations.
# All captured memories must be reviewed for PHI before storage.
# """

# Global additional guidance (applies to all LLM operations).
# Use this for cross-cutting concerns like security policies or quality standards.
# additional_guidance = """
# When analyzing content:
# - Pay special attention to PCI-DSS compliance for payment-related code
# - Flag any hardcoded credentials or API keys as security risks
# - Prioritize capturing architectural decisions over implementation details
# """

# Per-operation customizations - add guidance specific to each operation type.
[prompt.capture]
# additional_guidance = "Be extra conservative with captures in this repository."

[prompt.search]
# additional_guidance = "Prioritize recent memories over older ones."

[prompt.enrichment]
# additional_guidance = "Include compliance-related tags when applicable."

[prompt.consolidation]
# additional_guidance = "Preserve all security-related memories during consolidation."
